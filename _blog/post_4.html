---
title: "Backprop in Neural Networks"
collection: blog
permalink: /blog/post_4
excerpt: 'Backprop in Neural Networks'
date: 2017-03-01
---

<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width">
  <title>MathJax example</title>
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
</head>
<body>
<p><span class="math display">\[\frac{\partial Loss}{\partial b_{2}} = \frac{\partial Loss}{\partial z_{2}} * \frac{\partial z_{2}}{\partial b_{2}} = (y-\hat{y})
\label{eqn:sixteen}\]</span></p>
<p><span class="math display">\[\begin{aligned}
\frac{\partial Loss}{\partial W_{1}} &amp;= \frac{\partial Loss}{\partial z_{2}} * \frac{\partial z_{2}}{\partial z_{1}} * \frac{\partial z_{1}}{\partial W_{1}} \\
&amp;= \frac{\partial Loss}{\partial z_{2}} * \frac{\partial z_{2} }{\partial tanh(z_{1})} * \frac{\partial tanh(z_{1})}{\partial z_{1}} * \frac{\partial z_{1}}{\partial W_{1}}\\
&amp;= x^T (1-tanh^2Z_{1}) (y-\hat{y}) W_{2}^T
\label{eqn:seventeen}\end{aligned}\]</span></p>
</body>
</html>
